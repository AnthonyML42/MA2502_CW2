{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb425f-7288-447d-a604-159c6572849e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "list.of.packages <- c(\"tidyverse\", \"data.table\", \"dtplyr\", \"lme4\", \"lmerTest\", \"pROC\", \"matrixStats\", \"glmnet\", \"broom\")\n",
    "new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\n",
    "if(length(new.packages)) install.packages(new.packages)\n",
    "\n",
    "library(tidyverse)\n",
    "library(data.table)\n",
    "library(dtplyr) # Use dplyr syntax, but with a datatable backend - faster.\n",
    "library(lme4)\n",
    "library(lmerTest)\n",
    "library(pROC)\n",
    "library(caTools)\n",
    "library(matrixStats)\n",
    "library(glmnet)\n",
    "library(broom)\n",
    "library(glue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c240597-4060-4862-a334-d99d9a78d27d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "raw_shots <- read_csv(\"../Data/NBA_Shots_Raw.csv\")\n",
    "player_info <- read_csv(\"../Data/Player_Info.csv\")\n",
    "player_salary <- read_csv(\"../Data/Player_Salary.csv\")\n",
    "player_info <- player_info %>% mutate(PLAYER_NAME = paste(First_Name, Surname))\n",
    "player_salary <- player_salary %>% rename(PLAYER_NAME = Name)\n",
    "clean_shots <- read_csv(\"../Data/NBA_Shots_Clean_Example.csv\")\n",
    "common_player_info <- read_csv(\"../Data/wyatt_basketball/csv/common_player_info.csv\")\n",
    "common_player_info <- common_player_info %>% mutate(PLAYER_NAME = paste(first_name, last_name))\n",
    "height_2014 <- read_csv(\"../Data/NBA-Height-Weight/CSVs/Yearly/2014.csv\") # https://github.com/simonwarchol/NBA-Height-Weight\n",
    "height_2014 <- height_2014 %>% rename(PLAYER_NAME = Name)\n",
    "\n",
    "\n",
    "typos <- c(\n",
    "    \"Time Hardaway Jr\" = \"Tim Hardaway Jr\",\n",
    "    \"Steve Adams\" = \"Steven Adams\",\n",
    "    \"Jose Juan Barea\" = \"Jj Barea\",\n",
    "    \"Glen Rice Jr\" = \"Glen Rice\",\n",
    "    \"Charles Hayes\" = \"Chuck Hayes\", # technically correct but more sources with chuck\n",
    "    \"Ishmael Smith\" = \"Ish Smith\", # as above\n",
    "    \"Patrick Mills\" = \"Patty Mills\", # etc\n",
    "    \"Na Nene\" = \"Nene\",\n",
    "    \"Jose Barea\" = \"Jj Barea\"\n",
    ")\n",
    "\n",
    "replace_strings <- function(df, replacements) {\n",
    "    replacements <- unlist(replacements, use.names = TRUE)\n",
    "\n",
    "    df %>% mutate(across(where(is.character), ~ str_replace_all(., replacements)))\n",
    "}\n",
    "\n",
    "\n",
    "# Trying to standardise naming, works in almost every case!\n",
    "clean_name <- function(name) {\n",
    "  name %>%\n",
    "    str_replace_all(\"-\", \" \") %>%\n",
    "    str_replace_all(\"'\", \"\") %>%\n",
    "    str_remove_all(\"\\\\.\") %>%\n",
    "    str_to_title()\n",
    "}\n",
    "\n",
    "player_info <- player_info %>%\n",
    "    mutate(PLAYER_NAME = clean_name(PLAYER_NAME))\n",
    "\n",
    "           \n",
    "clean_shots <- clean_shots %>%\n",
    "    mutate(PLAYER_NAME = clean_name(PLAYER_NAME),\n",
    "          CLOSEST_DEFENDER = clean_name(CLOSEST_DEFENDER))\n",
    "\n",
    "common_player_info <- common_player_info %>%\n",
    "    mutate(PLAYER_NAME = clean_name(PLAYER_NAME)) %>%\n",
    "    filter(person_id != 779) # filtering out glen rice sr. by hand\n",
    "\n",
    "height_2014 <- height_2014 %>%\n",
    "    mutate(PLAYER_NAME = clean_name(PLAYER_NAME))\n",
    "\n",
    "\n",
    "clean_shots <- replace_strings(clean_shots, typos)\n",
    "player_info <- replace_strings(player_info, typos)\n",
    "common_player_info <- replace_strings(common_player_info, typos)\n",
    "height_2014 <- replace_strings(height_2014, typos)\n",
    "\n",
    "# Explicit case because of his name and interactions with the regex\n",
    "player_info <- player_info %>% mutate(across(where(is.character), ~ str_replace_all(., \"Luc Mbah\", \"Luc Mbah A Moute\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d111f8-a65d-45c8-91bf-9333cff7613a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "colnames(clean_shots)\n",
    "colnames(player_info)\n",
    "colnames(player_salary)\n",
    "colnames(height_2014)\n",
    "colnames(common_player_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a2b07-c939-471f-90d1-88920c260a20",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 7)\n",
    "\n",
    "s <- raw_shots %>% \n",
    "    left_join(player_info %>% select(Pos, PLAYER_NAME), by = \"PLAYER_NAME\") %>%\n",
    "    filter(!is.na(Pos)) %>%\n",
    "    select(SHOT_DIST, Pos)\n",
    "\n",
    "ggplot(s, aes(x = SHOT_DIST)) +\n",
    "    geom_histogram(bins = 30, fill = \"blue\", color = \"black\", alpha = 0.5) +\n",
    "    facet_wrap(~ Pos) +\n",
    "    labs(title = \"Shot Distance Distribution by Position\",\n",
    "       x = \"Shot Distance (feet)\",\n",
    "       y = \"Frequency\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b91f1-00a2-4a8a-a8fb-b4681e93205d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Listings of top 2pt/3pt scorers. Can be deleted, but ideas important for later.\n",
    "\n",
    "l1 <- raw_shots %>%\n",
    "    left_join(player_info %>% select(Pos, PLAYER_NAME), by = \"PLAYER_NAME\", relationship=\"many-to-many\") %>%\n",
    "    filter(!is.na(Pos)) %>%\n",
    "    group_by(PLAYER_NAME, Pos) %>% \n",
    "    summarize(tot_FGM = sum(FGM), .groups=\"drop\") %>% \n",
    "    arrange(desc(tot_FGM))\n",
    "l2 <- raw_shots %>% \n",
    "    filter(FGM == 1) %>% \n",
    "    group_by(PLAYER_NAME) %>%\n",
    "    summarise(\n",
    "        total_FGM = n(),\n",
    "        pct_3pt = sum(PTS_TYPE == 3),\n",
    "        pct_2pt = sum(PTS_TYPE == 2)\n",
    "    ) %>%\n",
    "    left_join(player_info %>% select(Pos, PLAYER_NAME, Team, Age), by = \"PLAYER_NAME\", relationship=\"many-to-many\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7834ce-dba1-4eb7-8164-4eab5e9424f3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# How many unique players are there in each dataset?\n",
    "\n",
    "clean_shots %>% summarise(unique_players = n_distinct(PLAYER_NAME))\n",
    "player_info %>% summarise(unique_players = n_distinct(PLAYER_NAME))\n",
    "player_salary %>% summarise(unique_players = n_distinct(PLAYER_NAME))\n",
    "\n",
    "# Why is the first number significantly different from the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19a64c-2571-4083-90c4-9be5e238b22f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# If the points are close at the end of the third quarter, is the home team more likely to take the win in subsequent period(s)?\n",
    "# Note this approach doesn't include every point as the data we have is incomplete (pointed out during lab session)\n",
    "\n",
    "home_games <- clean_shots %>%\n",
    "    filter(LOCATION == \"H\") %>%\n",
    "    select(GAME_ID, HOME_TEAM, AWAY_TEAM, WIN_LOSE, FINAL_MARGIN) %>%\n",
    "    distinct(GAME_ID, .keep_all=TRUE)\n",
    "\n",
    "# We test the home win percentage directly first\n",
    "\n",
    "home_games %>% summarise(total = n(), home_wins = sum(WIN_LOSE == \"W\"))\n",
    "\n",
    "# So the home team is statistically more likely to win a game\n",
    "\n",
    "binom.test(x=506, n=904, p=0.5, alternative=\"greater\")\n",
    "\n",
    "home_advantage_p3 <- clean_shots %>%\n",
    "    filter(PERIOD <= 3) %>%\n",
    "    mutate(pts = PTS_TYPE * SUCCESS) %>%\n",
    "    group_by(GAME_ID, LOCATION) %>%\n",
    "    summarise(total_pts = sum(pts), .groups = \"drop\") %>%\n",
    "    pivot_wider(names_from = LOCATION, values_from = total_pts, names_prefix = \"pts_\") %>%\n",
    "    left_join(home_games, by=\"GAME_ID\") %>%\n",
    "    rename(HOME_RESULT = WIN_LOSE) %>%\n",
    "    mutate(pts_diff = abs(pts_H - pts_A)) %>%\n",
    "    filter(pts_diff <= 3) %>%\n",
    "    summarise(\n",
    "        home_pct_win = sum(HOME_RESULT == \"W\")/n(),\n",
    "        home_wins = sum(HOME_RESULT == \"W\"),\n",
    "        total_games = n()\n",
    "    )\n",
    "\n",
    "home_advantage_p3\n",
    "\n",
    "binom.test(x=home_advantage_p3$home_wins, n=home_advantage_p3$total_games, p=0.5, alternative=\"greater\")\n",
    "\n",
    "# It turns out this isn't a significant effect, maybe we can try using FINAL_MARGIN, which is the point difference at the end.\n",
    "\n",
    "home_advantage_fm <- home_games %>% \n",
    "    filter(abs(FINAL_MARGIN) <= 3) %>%\n",
    "    summarise(home_pct_win = sum(WIN_LOSE == \"W\")/n(),\n",
    "             home_wins = sum(WIN_LOSE == \"W\"),\n",
    "             total_games = n())\n",
    "\n",
    "home_advantage_fm\n",
    "\n",
    "# Even worse! Maybe it's actually a detriment to be the home team in fact? Let's check.\n",
    "\n",
    "binom.test(x = home_advantage_fm$home_wins, n = home_advantage_fm$total_games, p=0.5, alternative = \"less\")\n",
    "\n",
    "# Unfortunately we don't have significance here either!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b98bc-cd50-4684-9e6a-ce32e4b7146e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Heights like 6-4 are very annoying, convert them to cm here!\n",
    "\n",
    "convert_to_cm <- function(feet_inches) {\n",
    "  split_height <- strsplit(feet_inches, \"-\")\n",
    "  \n",
    "  feet <- sapply(split_height, function(x) as.numeric(x[1]))\n",
    "  inches <- sapply(split_height, function(x) as.numeric(x[2]))\n",
    "  \n",
    "  cm_height <- (feet * 30.48) + (inches * 2.54)\n",
    "  \n",
    "  return(cm_height)\n",
    "}\n",
    "convert_to_cm <- Vectorize(convert_to_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edcfde0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "predictors <- c(\"GAME_ID\", \"PLAYER_NAME\", \"CLOSEST_DEFENDER\" ,\"SHOT_DIST\", \"PTS_TYPE\",\n",
    "                \"CLOSE_DEF_DIST\", \"SHOT_CLOCK\", \"TOUCH_TIME\", \"PERIOD\", \"DRIBBLES\",\n",
    "                \"SUCCESS\")\n",
    "\n",
    "# Join in height information one dataset at a time. \n",
    "# Since our shot data is our \"left\" dataset for the join, start by joining on unique players (shooters) and defenders.\n",
    "\n",
    "distinct_players_and_defenders <- union(\n",
    "    clean_shots %>% distinct(PLAYER_NAME),\n",
    "    clean_shots %>% distinct(CLOSEST_DEFENDER) %>% rename(PLAYER_NAME = CLOSEST_DEFENDER)\n",
    ")\n",
    "\n",
    "player_height_pos <- distinct_players_and_defenders %>%\n",
    "    left_join(player_info %>% select(PLAYER_NAME, Height, Pos), by=\"PLAYER_NAME\") %>%\n",
    "    rename(H1 = Height)\n",
    "\n",
    "player_height_pos <- player_height_pos %>%\n",
    "    left_join(common_player_info %>% select(PLAYER_NAME, height, position), by=\"PLAYER_NAME\", relationship = \"many-to-many\") %>%\n",
    "    rename(H2 = height)\n",
    "   \n",
    "player_height_pos <- player_height_pos %>%\n",
    "    left_join(height_2014 %>% select(PLAYER_NAME, \"Height(Feet-Inches)\"), by=\"PLAYER_NAME\") %>%\n",
    "    rename(H3 = \"Height(Feet-Inches)\") \n",
    "# Look at overlaps/ number of NAs in different height data now, then choose a method to combine the heights.\n",
    "# H3 all NA count is the important metric here, these are the players which aren't present in any of our height datasets.\n",
    "\n",
    "\n",
    "player_height_pos %>%\n",
    "  group_by(PLAYER_NAME) %>%\n",
    "  summarise(\n",
    "    H1_na = any(is.na(H1)),\n",
    "    H2_na = any(is.na(H2)),\n",
    "    H3_na = any(is.na(H3)),\n",
    "    H_all_na = all(is.na(H1) & is.na(H2) & is.na(H3))\n",
    "  ) %>%\n",
    "  summarise(\n",
    "    H1_na_count = sum(H1_na),\n",
    "    H2_na_count = sum(H2_na),\n",
    "    H3_na_count = sum(H3_na),\n",
    "    H_all_na_count = sum(H_all_na)\n",
    "  )\n",
    "\n",
    "\n",
    "# For example we're using the following rule below: Use the height data from the course if it exists, otherwise take the average of the other two.\n",
    "# Note, in the case one of the other two heights is NA it will use the valid one.\n",
    "\n",
    "player_height_pos <- player_height_pos %>%\n",
    "    mutate(\n",
    "    H2 = ifelse(!is.na(H2), convert_to_cm(H2), NA),\n",
    "    H3 = ifelse(!is.na(H3), convert_to_cm(H3), NA),\n",
    "    HEIGHT = case_when(\n",
    "        !is.na(H1) ~ H1,\n",
    "        is.na(H1) ~ rowMeans2(cbind(H2, H3), na.rm = TRUE),\n",
    "        TRUE ~ NA_real_\n",
    "    ))\n",
    "\n",
    "# Finally join the \"more complete\" height data onto the shot data.\n",
    "# Double join to get the defenders height data too - trick with renaming columns.\n",
    "# After we have a complete model dataset here, we can split it up and only then we can convert to factors.\n",
    "# Ignoring overtime for now.\n",
    "\n",
    "model_data_clean <- clean_shots %>% \n",
    "    select(all_of(predictors)) %>%\n",
    "    left_join(player_height_pos %>% select(PLAYER_NAME, HEIGHT), by=\"PLAYER_NAME\", relationship = \"many-to-many\") %>%\n",
    "    rename(SHOOTER_HEIGHT = HEIGHT) %>%\n",
    "    left_join(player_height_pos %>% select(PLAYER_NAME, HEIGHT) %>% rename(CLOSEST_DEFENDER = PLAYER_NAME), \n",
    "        by=\"CLOSEST_DEFENDER\", relationship = \"many-to-many\") %>%\n",
    "    rename(DEFENDER_HEIGHT = HEIGHT) %>%\n",
    "    mutate(SHOOTER_HEIGHT_ADV = SHOOTER_HEIGHT - DEFENDER_HEIGHT) %>%\n",
    "    filter(PERIOD <= 4)\n",
    "\n",
    "\n",
    "# Using height data is hard and some players aren't present in any of the three height datasets I found.\n",
    "# Who are these missing players? Do this in two steps...\n",
    "\n",
    "shooters_na <- model_data_clean %>%\n",
    "    filter(is.na(SHOOTER_HEIGHT)) %>%\n",
    "    distinct(name = PLAYER_NAME)\n",
    "\n",
    "defenders_na <- model_data_clean %>%\n",
    "    filter(is.na(DEFENDER_HEIGHT)) %>%\n",
    "    distinct(name = CLOSEST_DEFENDER)\n",
    "\n",
    "bind_rows(shooters_na, defenders_na) %>%\n",
    "    distinct() %>%\n",
    "    rename(missing_players =  name)\n",
    "\n",
    "model_data_clean <- na.omit(model_data_clean)\n",
    "\n",
    "# If we restrict ourselves to looking at the height data from this module we can identify a few players with problems. \n",
    "# For example, John Salmons played for NOP and was traded to PHX midseason.\n",
    "# If he were in the dataset, what would his team be? Brandan Wright is another example BOS->PHX (trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb64b51",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Scale everything so we can compare the weight sizes, also scaling is required for lasso regression.\n",
    "# Make an all_shots dataset, which is the only one we do the test/train split for because we want to examine the AUC.\n",
    "model_data <- model_data_clean %>%\n",
    "    mutate(across(c(\"GAME_ID\", \"PLAYER_NAME\", \"CLOSEST_DEFENDER\", \"PERIOD\", \"SUCCESS\", \"PTS_TYPE\"), as.factor))\n",
    "    \n",
    "model_data_scaled <- model_data %>% mutate(across(where(is.numeric), scale))\n",
    "\n",
    "set.seed(0)\n",
    "\n",
    "# Base r approach for model test/train split. Avoids using caret\n",
    "train_indices <- sample(1:nrow(model_data), size = 0.75 * nrow(model_data))\n",
    "train_data <- model_data_scaled[train_indices, ]\n",
    "test_data <- model_data_scaled[-train_indices, ]\n",
    "\n",
    "train_data <- na.omit(train_data)\n",
    "test_data <- na.omit(test_data)\n",
    "\n",
    "# A note on model specification. We're not putting PTS_TYPE here initially because of how R deals with factors.\n",
    "# If you do add PTS_TYPE, it will show PTS_TYPE3 as being a significant effect, and say nothing about PTS_TYPE2. \n",
    "# This is because 2 is chosen as the baseline for the model. Instead we deal with this afterwards\n",
    "\n",
    "log_model <- glm(SUCCESS ~ SHOT_DIST + CLOSE_DEF_DIST + TOUCH_TIME + SHOOTER_HEIGHT_ADV + PERIOD + SHOT_CLOCK + DRIBBLES,  \n",
    "                 data=train_data, family=binomial(link=\"logit\"))\n",
    "\n",
    "# Mixed model tries to account for variance between games and players. Doesn't come to very much variance it turns out.\n",
    "# Could be because of under-specification. No need to include mixed model in report.\n",
    "\n",
    "#log_mixed_model <- glmer(SUCCESS ~ SHOT_DIST + CLOSE_DEF_DIST + TOUCH_TIME + SHOOTER_HEIGHT_ADV + PERIOD + SHOT_CLOCK\n",
    "#                         + (1 | GAME_ID) + (1 | PLAYER_NAME),\n",
    "#                    data = train_data,\n",
    "#                   family=binomial(link = \"logit\"),\n",
    "#                        nAGQ = 0)\n",
    "\n",
    "## the output will explode if you put GAME_ID or PLAYER_NAME in here \n",
    "x_train <- model.matrix(SUCCESS ~ SHOT_DIST + CLOSE_DEF_DIST + TOUCH_TIME + \n",
    "                        SHOOTER_HEIGHT_ADV + PERIOD + SHOT_CLOCK, data = train_data)[, -1]\n",
    "y_train <- train_data$SUCCESS\n",
    "cv.out <- cv.glmnet(x_train, y_train, family = \"binomial\", alpha = 1, type.measure = \"auc\", nfolds=10)\n",
    "plot(cv.out)\n",
    "lambda_opt <- cv.out$lambda.1se\n",
    "\n",
    "x_test <- model.matrix(SUCCESS ~ SHOT_DIST + CLOSE_DEF_DIST + TOUCH_TIME + \n",
    "                       SHOOTER_HEIGHT_ADV + PERIOD + SHOT_CLOCK, data = test_data)[, -1]\n",
    "y_test <- test_data$SUCCESS\n",
    "\n",
    "log_lasso_model <- glmnet(x_train, y_train, family = \"binomial\", alpha=1, lambda=lambda_opt, standardize=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64954be-36f8-41b0-ba9a-e59f46970ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating the coefficients and if they are significant.\n",
    "# At this point there is no splitting the model for only 2 pointers/ only superstars etc. This comes after.\n",
    "summary(log_model)\n",
    "log_lasso_model$beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bced04-e4e3-455a-8d88-c02b363ad7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with just the regular log model, let's see what happens to the weights if we make a model for 2 and 3 pointers separately.\n",
    "# Fit with the whole dataset this time, we only need a train/test split for lasso and computing ROC.\n",
    "# Finally we fit a models for superstar players, and I've excluded them from the normal data but maybe this is pedantic.\n",
    "\n",
    "superstars = c(\"Steph Curry\", \"Anthony Davis\", \"Lebron James\", \"James Harden\", \"Russel Westbrook\", \"Kyrie Irving\",\n",
    "              \"Demarcus Cousins\", \"Klay Thompson\", \"Dwayne Wade\", \"Damian Lillard\") # This is arbitrary, so this is just a team of good players.\n",
    "\n",
    "model_data_2pt <- model_data_scaled %>% filter(PTS_TYPE == 2 & !PLAYER_NAME %in% superstars)\n",
    "model_data_3pt <- model_data_scaled %>% filter(PTS_TYPE == 3 & !PLAYER_NAME %in% superstars)\n",
    "model_data_super <- model_data_scaled %>% filter(PLAYER_NAME %in% superstars)\n",
    "model_data_super_2pt <- model_data_super %>% filter(PTS_TYPE == 2)\n",
    "model_data_super_3pt <- model_data_super %>% filter(PTS_TYPE == 3)\n",
    "\n",
    "# Repetitive but only to make sure the models are correct. A more concise syntax can be used if I filtered the data to only have the predictor cols.\n",
    "\n",
    "log_model_2pt <- glm(SUCCESS ~ SHOT_DIST + CLOSE_DEF_DIST + TOUCH_TIME + SHOOTER_HEIGHT_ADV  + DRIBBLES + SHOT_CLOCK, \n",
    "                     data = model_data_2pt, family = binomial(link = \"logit\"))\n",
    "log_model_3pt <- glm(SUCCESS ~ SHOT_DIST + CLOSE_DEF_DIST + TOUCH_TIME + SHOOTER_HEIGHT_ADV + DRIBBLES + SHOT_CLOCK, \n",
    "                     data = model_data_3pt, family = binomial(link = \"logit\"))\n",
    "#log_model_super <- glm(SUCCESS ~ SHOT_DIST + CLOSE_DEF_DIST + TOUCH_TIME + SHOOTER_HEIGHT_ADV + SHOT_CLOCK + DRIBBLES + SHOT_CLOCK, \n",
    "#                     data = model_data_super, family = binomial(link = \"logit\"))\n",
    "\n",
    "log_model_super_2pt <- glm(SUCCESS ~ SHOT_DIST + CLOSE_DEF_DIST + TOUCH_TIME + SHOOTER_HEIGHT_ADV + DRIBBLES + SHOT_CLOCK, \n",
    "                     data = model_data_super_2pt, family = binomial(link = \"logit\"))\n",
    "log_model_super_3pt <- glm(SUCCESS ~ SHOT_DIST + CLOSE_DEF_DIST + TOUCH_TIME + SHOOTER_HEIGHT_ADV + DRIBBLES + SHOT_CLOCK, \n",
    "                     data = model_data_super_3pt, family = binomial(link = \"logit\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cabb6c-608c-430f-9f4d-5d3d539e5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the coefficients, use Wald's CI to make it easy\n",
    "coefs_plot <- bind_rows(\n",
    "    tidy(log_model_2pt)   %>% mutate(model = glue(\"2PT, n={nrow(model_data_2pt)}\")),\n",
    "    tidy(log_model_3pt)   %>% mutate(model = glue(\"3PT, n={nrow(model_data_3pt)}\")),\n",
    "    tidy(log_model_super_2pt) %>% mutate(model = glue(\"Superstar 2PT, n={nrow(model_data_super_2pt)}\")),\n",
    "    tidy(log_model_super_3pt) %>% mutate(model = glue(\"Superstar 3PT, n={nrow(model_data_super_3pt)}\")),\n",
    "  ) %>%\n",
    "  filter(term != \"(Intercept)\") %>%\n",
    "  mutate(\n",
    "    # Wald CI here, 1.96 is a normal dist value.\n",
    "    lower = estimate - 1.96 * std.error,\n",
    "    upper = estimate + 1.96 * std.error,\n",
    "    sig   = p.value <= 0.05\n",
    "  )\n",
    "options(repr.plot.width=15, repr.plot.height=8)\n",
    "ggplot(coefs_plot, aes(x = estimate, y = term, colour = model, shape = sig)) +\n",
    "  geom_vline(xintercept = 0, linetype = \"dashed\", colour = \"grey50\") +\n",
    "  geom_errorbarh(aes(xmin = lower, xmax = upper),\n",
    "                 height = 0.2,\n",
    "                 linewidth = 1.2,\n",
    "                 position = position_dodge(width = 0.7)) +\n",
    "  geom_point(position = position_dodge(width = 0.7), size = 4) +\n",
    "  scale_color_brewer(palette = \"Dark2\") +\n",
    "  scale_shape_manual(\n",
    "    values = c(`FALSE` = 1, `TRUE` = 16),\n",
    "    labels = c(`FALSE` = \"Not significant\", `TRUE` = \"Significant\")\n",
    "  ) +\n",
    "  labs(\n",
    "    title  = \"Model Coefficients\",\n",
    "    x      = \"Log-Odds Estimate\",\n",
    "    y      = NULL,\n",
    "    colour = \"Model\",\n",
    "    shape  = \"Significance\"\n",
    "  ) +\n",
    "  theme_minimal(base_size = 14) +\n",
    "  theme(\n",
    "    panel.grid.major.y = element_blank(),\n",
    "    axis.text.y = element_text(face = \"bold\"),\n",
    "    plot.title = element_text(face = \"bold\"),\n",
    "    legend.position    = \"bottom\"\n",
    "  )\n",
    "\n",
    "# The large CI on superstart 3pts is strange. We expect the sample sizes to be different, let's check. (Added to plot now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269ddb0-2b1d-48d6-b5b2-e3d518dc1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual deviance and ROC plots. Probably don't include deviance in report but AUROC could work.\n",
    "# Phrasing would be: AUROC low so we know these features don't fully explain if a shot will go in or not.\n",
    "# (Deviance tells the same story)\n",
    "\n",
    "model_roc <- function(model, test_data) {\n",
    "    pred_prob <- predict(model, newdata = test_data, type=\"response\")\n",
    "    roc_obj <- roc(test_data$SUCCESS, as.vector(pred_prob), ci = TRUE, quiet = TRUE)\n",
    "    return(roc_obj)\n",
    "}\n",
    "\n",
    "residual_deviance_plot <- function(model, title_str) {\n",
    "    plot_data <- data.frame(\n",
    "        fitted = fitted(model),\n",
    "        residuals = residuals(model, type = \"deviance\")\n",
    "    )\n",
    "    \n",
    "    resid_plot <- ggplot(plot_data, aes(x = fitted, y = residuals)) +\n",
    "    geom_point(alpha = 0.3, size = 0.8) +\n",
    "    geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") + \n",
    "    geom_smooth(method = \"gam\", formula = y ~ s(x, bs = \"cs\")) + # the default warning message was annoying\n",
    "    labs(\n",
    "        title = paste0(title_str, \": Residuals vs Fitted\"),\n",
    "        subtitle = \"Deviance residuals plotted against predicted probabilities\",\n",
    "        x = \"Fitted values (predicted probabilities)\",\n",
    "        y = \"Deviance residuals\"\n",
    "    ) +\n",
    "    theme_bw() +\n",
    "    theme(\n",
    "        panel.grid.minor = element_blank(),\n",
    "        panel.grid.major = element_line(color = \"grey90\"),\n",
    "        plot.title = element_text(hjust = 0.5, face = \"bold\"),\n",
    "        plot.subtitle = element_text(hjust = 0.5, color = \"darkgrey\")\n",
    "    )\n",
    "    return(resid_plot)\n",
    "}\n",
    "\n",
    "model_roc(log_model, test_data)\n",
    "residual_deviance_plot(log_model, \"Logistc model\")\n",
    "\n",
    "\n",
    "pred_prob <- predict(log_model, newdata = test_data, type=\"response\")\n",
    "\n",
    "roc_obj <- roc(test_data$SUCCESS, as.vector(pred_prob), ci=TRUE)\n",
    "plot(roc_obj, col = \"#2C3E50\", lwd = 2, main = \"ROC Curve for Logistic Model\")\n",
    "auc_text <- paste0(\"AUC = \", round(auc(roc_obj), 3))\n",
    "legend(\"bottomright\", legend = auc_text, col = \"#2C3E50\", lwd = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5f50f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get the mean touch time in each period per game, then convert to factors for plotting/etc.\n",
    "\n",
    "period_mtt <- clean_shots %>%\n",
    "    group_by(GAME_ID, PERIOD) %>%\n",
    "    summarise(mean_tt = mean(TOUCH_TIME))\n",
    "\n",
    "period_mtt <- period_mtt %>% filter(PERIOD <= 4) %>% mutate_at(c(\"PERIOD\", \"GAME_ID\"), as.factor)\n",
    "\n",
    "\n",
    "ggplot(period_mtt, aes(x = PERIOD, y = mean_tt)) +\n",
    "    geom_boxplot() +\n",
    "    labs(\n",
    "    x = \"Period\",\n",
    "    y = \"Mean Touch Time\",\n",
    "    title = \"Distribution of Mean Touch Time by Period\"\n",
    "    )\n",
    "\n",
    "# How many overtime games did we exclude from this analysis?\n",
    "clean_shots %>% \n",
    "    filter(PERIOD >= 5) %>%\n",
    "    summarise(overtime_games = n_distinct(GAME_ID))\n",
    "\n",
    "# Do a simple anova to see if we have a significant difference\n",
    "model <- aov(mean_tt ~ PERIOD, data = period_mtt)\n",
    "summary(model)\n",
    "\n",
    "# since we have a significant difference, we now ask which period is significantly different from the rest? This is a post-hoc test.\n",
    "TukeyHSD(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a243e-9b95-4122-ac89-de544c4e1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about touch time when the shot is contested?\n",
    "contested_shots <- model_data_clean %>%\n",
    "    mutate(contested = case_when(\n",
    "        CLOSE_DEF_DIST <= 4 ~ \"Contested\",\n",
    "        .default = \"Not contested\"  \n",
    "    )) %>%\n",
    "    group_by(GAME_ID, contested) %>%\n",
    "    summarise(mean_tt = mean(TOUCH_TIME), .groups = \"drop\")\n",
    "\n",
    "\n",
    "ggplot(contested_shots, aes(x = contested, y = mean_tt, fill = contested)) +\n",
    "  geom_boxplot(alpha = 0.7, outlier.shape = NA) +\n",
    "  scale_fill_manual(values = c(\"Contested\" = \"#E69F00\", \"Not contested\" = \"#56B4E9\")) +\n",
    "  labs(\n",
    "    title = \"Distribution of Mean TT by Contested Status\",\n",
    "    x     = \"Contested?\",\n",
    "    y     = \"Mean TT\"\n",
    "  ) +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"none\")\n",
    "\n",
    "# There is definitely more to this than meets the eye...\n",
    "# How about the success probability of contested shots?\n",
    "\n",
    "contested_success_rate <- model_data_clean %>%\n",
    "    mutate(contested = case_when(\n",
    "        CLOSE_DEF_DIST <= 4 ~ \"Contested\",\n",
    "        .default = \"Not contested\"  \n",
    "    )) %>% \n",
    "    summarise(total_shots = n(),\n",
    "             contested_shots = sum(contested == \"Contested\"),\n",
    "             contested_successful = sum(SUCCESS == 1 & contested == \"Contested\"),\n",
    "             prop = contested_successful/contested_shots)\n",
    "\n",
    "contested_success_rate\n",
    "\n",
    "\n",
    "binom.test(x=contested_success_rate$contested_successful, n=contested_success_rate$contested_shots, p=0.5, alternative=\"less\")\n",
    "# Finally a significant result, even though the conclusion isn't surprising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34424e7c-12e2-47f9-821a-ed108acf6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting here, but doesn't look too impressive.\n",
    "library(scatterplot3d)\n",
    "scatterplot3d(\n",
    "  y = model_data_clean$CLOSE_DEF_DIST,\n",
    "  x = model_data_clean$TOUCH_TIME,\n",
    "  z = model_data_clean$SHOT_DIST,\n",
    "  color = \"darkred\",\n",
    "  pch = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae20364-f920-48e7-b26d-2aeb609f1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lebron isn't the best player? Can it be?\n",
    "# Here it says that he only played 51 games, but official stats (ESPN/Basketball reference) say he played 69 games! (Regular season)\n",
    "# James Harden actually played in 81 games!\n",
    "model_data_clean %>%\n",
    "    mutate(pts = PTS_TYPE * SUCCESS) %>%\n",
    "    group_by(PLAYER_NAME) %>%\n",
    "    summarise(\n",
    "        total_pts   = sum(pts),\n",
    "        games_played = n_distinct(GAME_ID),\n",
    "        avg_pts_game = total_pts / games_played,\n",
    "        .groups = \"drop\"\n",
    "    ) %>% arrange(desc(avg_pts_game))\n",
    "\n",
    "\n",
    "model_data_clean %>% summarise(count = n_distinct(GAME_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32261b-3a4d-4d1c-97b4-0f978b9ed7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
